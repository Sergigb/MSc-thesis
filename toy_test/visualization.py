import pickle
import os
import json
import sys

import numpy as np
from sklearn.manifold import TSNE
import torchvision.transforms as transforms
import torch
import matplotlib.pyplot as plt
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from scipy.stats import kde
from matplotlib.lines import Line2D

sys.path.insert(1, '../')

from model import CNN
from data_loader import get_wiki_data_loader

mixture_model = True
was_pretrained = True
use_lda_labels = False  # use the labels generated by the LDA instead of the neural network
n_kernels = 3
n_topics = 2
batch_size = 128
model_path = '../models/toy_example15/models/model-epoch-12.pth'

emb_filename = '../data/2d-embeddings-toy-15-12.npy'
ids_filename = '../data/ids-embeddings-toy-15-12.pkl'
if mixture_model:
    alpha_filename = '../data/alpha-toy-15-12.npy'
    sigma_filename = '../data/sigma-toy-15-12.npy'


def rand_jitter(arr):
    stdev = .0005*(max(arr)-min(arr))
    return arr + np.random.randn(len(arr)) * stdev


def imscatter(x, y, image, ax=None, zoom=2.):
    if ax is None:
        ax = plt.gca()
    try:
        image = plt.imread(image)
    except TypeError:
        pass
    im = OffsetImage(image, zoom=zoom, cmap=plt.get_cmap('gray'))
    im.set_zorder(10)
    x, y = np.atleast_1d(x, y)
    artists = []
    for x0, y0 in zip(x, y):
        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)
        ab.set_zorder(10)
        artists.append(ax.add_artist(ab))
    ax.update_datalim(np.column_stack([x, y]))
    ax.autoscale()
    return artists

if use_lda_labels:
    X = []
    ids = []
    json_labels_path = 'training_labels2.json'

    with open(json_labels_path) as f:
        labels = json.load(f)
    for key in labels.keys():
        X.append(labels[key])
        ids.append(key)
    X = np.array(X)

else:
    if os.path.isfile(emb_filename):
        X = np.load(emb_filename)
        if mixture_model:
            alpha_values = np.load(alpha_filename)
            sigma_values = np.load(sigma_filename)
        with open(ids_filename, 'rb') as handle:
            ids = pickle.load(handle)
    else:
        transform = transforms.Compose([
            transforms.Resize((227, 227)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
            ])

        dataset_path = '../../datasets/ali/all_images/'
        json_labels_path = 'training_labels2.json'

        data_loader = get_wiki_data_loader(dataset_path, json_labels_path,
                                           transform, batch_size, shuffle=True,
                                           num_workers=8, return_ids=True)

        model = CNN(n_topics, n_kernels, out_dim=None, mixture_model=mixture_model, cnn='alexnet',
                    pretrained=was_pretrained)
        model.load_state_dict(torch.load(model_path))
        model.eval()

        if torch.cuda.is_available():
            model.cuda()

        X = []
        sigma_values = []
        alpha_values = []
        ids = []

        for step, (images, _, image_ids) in enumerate(data_loader):
            if torch.cuda.is_available():
                images = images.cuda()

            if mixture_model:
                alphas, sigmas, out = model(images)
            else:
                out = model(images)

            #ids.extend(list(image_ids))
            image_ids = list(image_ids)
            for i in range(out.shape[0]):
                embeddings = out[i, :].cpu().detach().numpy()
                if mixture_model:
                    alphas_ = alphas[i, :].cpu().detach().numpy()
                    sigmas_ = sigmas[i, :].cpu().detach().numpy()
                for j in range(n_kernels):
                    ids.append(image_ids[i])
                    X.append(embeddings[j*n_topics:(j+1)*n_topics])
                    if mixture_model:
                        alpha_values.append(alphas_[j])
                        sigma_values.append(sigmas_[j])

            print('Step ' + str(step+1) + '/' + str(len(data_loader)))
        print(len(X))
        X = np.array(X)
        if mixture_model:
            alpha_values = np.array(alpha_values)
            sigma_values = np.array(sigma_values)
        print(X.shape)
        print(len(ids))
        if mixture_model:
            print(alpha_values.shape)
            print(sigma_values.shape)

        with open(ids_filename, 'wb') as handle:
            pickle.dump(ids, handle, protocol=pickle.HIGHEST_PROTOCOL)

        np.save(emb_filename, X)
        if mixture_model:
            np.save(alpha_filename, alpha_values)
            np.save(sigma_filename, sigma_values)

        print("finished!")


# scatter random images
fig, ax = plt.subplots()
for i in range(5000):
    idx = int(np.random.choice(len(ids), 1))
    image_filename = ids[idx]
    image_filename = os.path.join('../../datasets/ali/all_images/', image_filename)
    imscatter(X[idx, 0], X[idx, 1], image_filename, zoom=0.20)

plt.show(block=False)


# plot consecutive pairs
fig, ax = plt.subplots()
i = 0
offset = 0  # must be even
while i < 250:
    i += 2
    ax.add_line(Line2D([X[i+offset, 0], X[i+offset+1, 0]],[X[i+offset, 1],
                        X[i+offset+1, 1]], linewidth=1, color='blue', zorder=10))
    ax.scatter([X[i+offset, 0], X[i+offset+1, 0]],[X[i+offset, 1],
                        X[i+offset+1, 1]], color='red', marker='*', zorder=0, s=8)
plt.autoscale()
plt.show(block=False)


# sigma visualization
# sigma_norm = (sigma_values-min(sigma_values)) / (max(sigma_values)-min(sigma_values))
fig1, ax1 = plt.subplots()
plt.scatter(rand_jitter(X[:, 0]), rand_jitter(X[:, 1]), c=sigma_values[:], s=64)
plt.clim(sigma_values.min(), sigma_values.max())
plt.colorbar()
plt.show(block=False)

# alpha visualization
# alpha_norm = (alpha_values-min(alpha_values)) / (max(alpha_values)-min(alpha_values))
fig1, ax1 = plt.subplots()
plt.scatter(X[:, 0], X[:, 1], c=alpha_values[:], s=64)
plt.clim(alpha_values.min(), alpha_values.max())
plt.colorbar()
plt.show()


# density visualization
# nbins = 1500
# k = kde.gaussian_kde([X_embedded[:, 0], X_embedded[:, 1]])
# xi, yi = np.mgrid[X_embedded[:, 0].min():X_embedded[:, 0].max():nbins * 1j,
#                   X_embedded[:, 0].min():X_embedded[:, 0].max():nbins * 1j]
# zi = k(np.vstack([xi.flatten(), yi.flatten()]))
#
# plt.pcolormesh(xi, yi, zi.reshape(xi.shape), cmap=plt.cm.Greens_r)
# plt.show()


#  scatter random images in a matrix form
# fig, ax = plt.subplots()
# x_min_width = np.min(X_embedded[:, 0])
# y_min_width = np.min(X_embedded[:, 1])
#
# X_embedded[:, 0] += abs(x_min_width)
# X_embedded[:, 1] += abs(y_min_width)
#
# fig, ax = plt.subplots()
# idxs = []
#
# for i in range(5000):
#     idx = int(np.random.choice(len(ids), 1))
#     idxs.append(idx)
#     image_filename = ids[idx]
#     image_filename = os.path.join('./../datasets/ImageCLEF_wikipedia/', image_filename)
#     imscatter(int(X_embedded[idx, 0]/4.5), int(X_embedded[idx, 1]/8), image_filename, zoom=0.2)
#
# plt.show()

